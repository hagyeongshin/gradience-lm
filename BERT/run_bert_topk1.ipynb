{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import pipeline\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from konlpy.tag import Kkma\n",
    "#from konlpy.utils import pprint\n",
    "#kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#https://huggingface.co/kykim/bert-kor-base\n",
    "#model.eval() for model information\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"kykim/bert-kor-base\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"kykim/bert-kor-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top_k can be adjusted from 1 (output with top probability) to tokenizer.vocab_size \n",
    "unmask = pipeline(task=\"fill-mask\", model=model, tokenizer=tokenizer, top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getentropy(q):\n",
    "    #entropy = -(q * np.log2(q))\n",
    "    entropy = -(q * np.log2(q) + (1-q) * np.log2(1-q))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(filename):\n",
    "    \"\"\"Run BERT for experiment items.\"\"\"\n",
    "    \n",
    "    data_path = \"{FILE}.csv\".format(FILE=filename)\n",
    "    vocab_dict = pd.read_pickle('vocab_pos_df.pickle').set_index('token').to_dict()['pos']\n",
    "    df_output = pd.read_csv(data_path)\n",
    "    \n",
    "    cond = []\n",
    "    item = []\n",
    "    text = []\n",
    "    pos = []\n",
    "    prob = []\n",
    "    surprisal = []\n",
    "    \n",
    "    with tqdm(total=df_output.shape[0]) as pbar:\n",
    "        for index, row in df_output.iterrows():\n",
    "            \n",
    "            condition = row['Condition name']\n",
    "            cond.append(condition)\n",
    "            \n",
    "            itemindex = row['Lexicalization']\n",
    "            item.append(itemindex)\n",
    "            \n",
    "            sentence = row['Item']\n",
    "            responses = unmask(sentence)\n",
    "                    \n",
    "            for dicts in responses:\n",
    "                for dict_entry in range(len(responses)):                \n",
    "                    for vocab in vocab_dict:\n",
    "                        if responses[dict_entry]['token_str'] == vocab:\n",
    "                            responses[dict_entry]['pos'] = vocab_dict[vocab]\n",
    "                            \n",
    "            text.append(responses[dict_entry]['token_str'])\n",
    "            pos.append(responses[dict_entry]['pos'])\n",
    "            prob.append(responses[dict_entry]['score'])\n",
    "            surprisal.append(-math.log2(responses[dict_entry]['score']))\n",
    "            #entropy.append(getentropy(responses[dict_entry]['score']))\n",
    "\n",
    "            pbar.update(1)\n",
    "    \n",
    "    df_output['text'] = text\n",
    "    df_output['pos'] = pos\n",
    "    df_output['prob'] = prob\n",
    "    df_output['surprisal'] = surprisal\n",
    "    \n",
    "    df_output.to_csv(\"{TASK}_topk1_output.csv\".format(TASK=filename), index=False)\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 360/360 [00:46<00:00,  7.80it/s]\n"
     ]
    }
   ],
   "source": [
    "output = main(\"3cond_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idx</th>\n",
       "      <th>Lexicalization</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Condition name</th>\n",
       "      <th>Item</th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>prob</th>\n",
       "      <th>surprisal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nc-nom</td>\n",
       "      <td>지은이 사실을 [MASK].</td>\n",
       "      <td>밝혔다</td>\n",
       "      <td>[(밝히, VV), (었, EPT), (다, EFN)]</td>\n",
       "      <td>0.103494</td>\n",
       "      <td>3.272378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>nc-nom</td>\n",
       "      <td>호준이 용돈을 [MASK].</td>\n",
       "      <td>.</td>\n",
       "      <td>[(., SF)]</td>\n",
       "      <td>0.179533</td>\n",
       "      <td>2.477681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>nc-nom</td>\n",
       "      <td>은지가 불을 [MASK].</td>\n",
       "      <td>끈다</td>\n",
       "      <td>[(끄, VV), (ㄴ다, EFN)]</td>\n",
       "      <td>0.117682</td>\n",
       "      <td>3.087038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>nc-nom</td>\n",
       "      <td>용준이 마중을 [MASK].</td>\n",
       "      <td>나왔어요</td>\n",
       "      <td>[(나오, VV), (았, EPT), (어요, EFN)]</td>\n",
       "      <td>0.165672</td>\n",
       "      <td>2.593596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>nc-nom</td>\n",
       "      <td>은영이 저녁을 [MASK].</td>\n",
       "      <td>먹는다</td>\n",
       "      <td>[(먹, VV), (는, EPT), (다, EFN)]</td>\n",
       "      <td>0.252464</td>\n",
       "      <td>1.985851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>355</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>nom-to</td>\n",
       "      <td>경희가 잘못을 일삼았다. 규호도 잘못을 [MASK].</td>\n",
       "      <td>했다</td>\n",
       "      <td>[(하, VV), (었, EPT), (다, EFN)]</td>\n",
       "      <td>0.665108</td>\n",
       "      <td>0.588340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>356</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>nom-to</td>\n",
       "      <td>호영이 싸움을 일으켰다. 은주도 싸움을 [MASK].</td>\n",
       "      <td>일어났다</td>\n",
       "      <td>[(일어나, VV), (었, EPT), (다, EFN)]</td>\n",
       "      <td>0.554497</td>\n",
       "      <td>0.850748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>357</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>nom-to</td>\n",
       "      <td>미진이 지갑을 잃었다. 윤호도 지갑을 [MASK].</td>\n",
       "      <td>찾았다</td>\n",
       "      <td>[(찾, VV), (았, EPT), (다, EFN)]</td>\n",
       "      <td>0.519524</td>\n",
       "      <td>0.944737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>nom-to</td>\n",
       "      <td>두호가 약속을 잊었다. 하원도 약속을 [MASK].</td>\n",
       "      <td>했다</td>\n",
       "      <td>[(하, VV), (었, EPT), (다, EFN)]</td>\n",
       "      <td>0.505473</td>\n",
       "      <td>0.984295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>nom-to</td>\n",
       "      <td>호섭이 문제를 제기했다. 윤아도 문제를 [MASK].</td>\n",
       "      <td>제기</td>\n",
       "      <td>[(제기, NNG)]</td>\n",
       "      <td>0.538661</td>\n",
       "      <td>0.892552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Idx  Lexicalization  Condition Condition name  \\\n",
       "0      0               1          1         nc-nom   \n",
       "1      1               2          1         nc-nom   \n",
       "2      2               3          1         nc-nom   \n",
       "3      3               4          1         nc-nom   \n",
       "4      4               5          1         nc-nom   \n",
       "..   ...             ...        ...            ...   \n",
       "355  355              56          6         nom-to   \n",
       "356  356              57          6         nom-to   \n",
       "357  357              58          6         nom-to   \n",
       "358  358              59          6         nom-to   \n",
       "359  359              60          6         nom-to   \n",
       "\n",
       "                              Item  text                              pos  \\\n",
       "0                  지은이 사실을 [MASK].   밝혔다   [(밝히, VV), (었, EPT), (다, EFN)]   \n",
       "1                  호준이 용돈을 [MASK].     .                        [(., SF)]   \n",
       "2                   은지가 불을 [MASK].    끈다             [(끄, VV), (ㄴ다, EFN)]   \n",
       "3                  용준이 마중을 [MASK].  나왔어요  [(나오, VV), (았, EPT), (어요, EFN)]   \n",
       "4                  은영이 저녁을 [MASK].   먹는다    [(먹, VV), (는, EPT), (다, EFN)]   \n",
       "..                             ...   ...                              ...   \n",
       "355  경희가 잘못을 일삼았다. 규호도 잘못을 [MASK].    했다    [(하, VV), (었, EPT), (다, EFN)]   \n",
       "356  호영이 싸움을 일으켰다. 은주도 싸움을 [MASK].  일어났다  [(일어나, VV), (었, EPT), (다, EFN)]   \n",
       "357   미진이 지갑을 잃었다. 윤호도 지갑을 [MASK].   찾았다    [(찾, VV), (았, EPT), (다, EFN)]   \n",
       "358   두호가 약속을 잊었다. 하원도 약속을 [MASK].    했다    [(하, VV), (었, EPT), (다, EFN)]   \n",
       "359  호섭이 문제를 제기했다. 윤아도 문제를 [MASK].    제기                      [(제기, NNG)]   \n",
       "\n",
       "         prob  surprisal  \n",
       "0    0.103494   3.272378  \n",
       "1    0.179533   2.477681  \n",
       "2    0.117682   3.087038  \n",
       "3    0.165672   2.593596  \n",
       "4    0.252464   1.985851  \n",
       "..        ...        ...  \n",
       "355  0.665108   0.588340  \n",
       "356  0.554497   0.850748  \n",
       "357  0.519524   0.944737  \n",
       "358  0.505473   0.984295  \n",
       "359  0.538661   0.892552  \n",
       "\n",
       "[360 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
